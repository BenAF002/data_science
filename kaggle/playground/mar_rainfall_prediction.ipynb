{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pressure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxtemp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temparature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mintemp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dewpoint",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "humidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloud",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sunshine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "winddirection",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "windspeed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rainfall",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9a9c2712-35f2-4627-b8f1-6ade32926804",
       "rows": [
        [
         "0",
         "1",
         "1017.4",
         "21.2",
         "20.6",
         "19.9",
         "19.4",
         "87.0",
         "88.0",
         "1.1",
         "60.0",
         "17.2",
         "1"
        ],
        [
         "1",
         "2",
         "1019.5",
         "16.2",
         "16.9",
         "15.8",
         "15.4",
         "95.0",
         "91.0",
         "0.0",
         "50.0",
         "21.9",
         "1"
        ],
        [
         "2",
         "3",
         "1024.1",
         "19.4",
         "16.1",
         "14.6",
         "9.3",
         "75.0",
         "47.0",
         "8.3",
         "70.0",
         "18.1",
         "1"
        ],
        [
         "3",
         "4",
         "1013.4",
         "18.1",
         "17.8",
         "16.9",
         "16.8",
         "95.0",
         "95.0",
         "0.0",
         "60.0",
         "35.6",
         "1"
        ],
        [
         "4",
         "5",
         "1021.8",
         "21.3",
         "18.4",
         "15.2",
         "9.6",
         "52.0",
         "45.0",
         "3.6",
         "40.0",
         "24.8",
         "0"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>pressure</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>temparature</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>cloud</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>16.9</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1024.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>18.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    day  pressure  maxtemp  temparature  mintemp  dewpoint  humidity  cloud  \\\n",
       "id                                                                            \n",
       "0     1    1017.4     21.2         20.6     19.9      19.4      87.0   88.0   \n",
       "1     2    1019.5     16.2         16.9     15.8      15.4      95.0   91.0   \n",
       "2     3    1024.1     19.4         16.1     14.6       9.3      75.0   47.0   \n",
       "3     4    1013.4     18.1         17.8     16.9      16.8      95.0   95.0   \n",
       "4     5    1021.8     21.3         18.4     15.2       9.6      52.0   45.0   \n",
       "\n",
       "    sunshine  winddirection  windspeed  rainfall  \n",
       "id                                                \n",
       "0        1.1           60.0       17.2         1  \n",
       "1        0.0           50.0       21.9         1  \n",
       "2        8.3           70.0       18.1         1  \n",
       "3        0.0           60.0       35.6         1  \n",
       "4        3.6           40.0       24.8         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\benak\\Python_Base_Dir\\data\\rainfall\\train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(r\"C:\\Users\\benak\\Python_Base_Dir\\data\\rainfall\\test.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                 1.0\n",
       "pressure         1019.5\n",
       "maxtemp            17.5\n",
       "temparature        15.8\n",
       "mintemp            12.7\n",
       "dewpoint           14.9\n",
       "humidity           96.0\n",
       "cloud              99.0\n",
       "sunshine            0.0\n",
       "winddirection      50.0\n",
       "windspeed          24.3\n",
       "Name: 2190, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df, test_df):\n",
    "    std_df, std_test_df = df.copy(), test_df.copy()\n",
    "    for c in std_df.columns[1:-1]: std_df[c] = (std_df[c] - std_df[c].mean()) / std_df[c].std()\n",
    "    for c in std_test_df.columns[1:]: std_test_df[c] = (std_test_df[c] - std_test_df[c].mean()) / std_test_df[c].std()\n",
    "    return std_df, std_test_df\n",
    "\n",
    "std_df, std_test_df = standardize(df, test_df)\n",
    "\n",
    "# need non-random split since data is time series\n",
    "def split(df, test_size=0.2):\n",
    "    n = int((len(df) * (1 - test_size)))\n",
    "    train = df.iloc[:n]\n",
    "    test = df.iloc[n:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.8682\n",
      "Val acc: 0.8699\n",
      "Val roc/auc: 0.7700113093742147\n"
     ]
    }
   ],
   "source": [
    "tr, val = split(std_df)\n",
    "Xtr, Ytr = tr.iloc[:, :-1], tr.iloc[:, -1]\n",
    "Xval, Yval = val.iloc[:, :-1], val.iloc[:, -1]\n",
    "\n",
    "lm = LogisticRegression(solver='newton-cg', max_iter=1000)\n",
    "lm.fit(Xtr, Ytr)\n",
    "Ypred = lm.predict(Xval)\n",
    "\n",
    "print(f'train acc: {accuracy_score(Ytr, lm.predict(Xtr)):.4f}')\n",
    "print(f'Val acc: {accuracy_score(Yval, Ypred):.4f}')\n",
    "print(f'Val roc/auc: {roc_auc_score(Yval, Ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.8910\n",
      "Val acc: 0.8607\n",
      "Val roc/auc: 0.7642309625534054\n"
     ]
    }
   ],
   "source": [
    "# try gradient boost on unstandardized data\n",
    "tr, val = split(df)\n",
    "Xtr, Ytr = tr.iloc[:, :-1], tr.iloc[:, -1]\n",
    "Xval, Yval = val.iloc[:, :-1], val.iloc[:, -1]\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(max_iter=1000, max_depth=1, random_state=42)\n",
    "\n",
    "hgb.fit(Xtr, Ytr)\n",
    "Ypred = hgb.predict(Xval)\n",
    "\n",
    "print(f'train acc: {accuracy_score(Ytr, hgb.predict(Xtr)):.4f}')\n",
    "print(f'Val acc: {accuracy_score(Yval, Ypred):.4f}')\n",
    "print(f'Val roc/auc: {roc_auc_score(Yval, Ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "{'l2_regularization': 0.1, 'learning_rate': 0.01, 'max_depth': 1, 'max_iter': 1000}\n",
      "0.8693072853072852\n",
      "HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.01,\n",
      "                               max_depth=1, max_iter=1000, random_state=42)\n",
      "train acc: 0.8739\n",
      "Val acc: 0.8699\n",
      "Val roc/auc: 0.7819803970846946\n"
     ]
    }
   ],
   "source": [
    "# cv tune hist gradient boosting classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [1000],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'l2_regularization': [0.1, 0.01, 0.001],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "grid = GridSearchCV(hgb, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid.fit(Xtr, Ytr)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "Ypred = grid.best_estimator_.predict(Xval)\n",
    "\n",
    "print(f'train acc: {accuracy_score(Ytr, grid.best_estimator_.predict(Xtr)):.4f}')\n",
    "print(f'Val acc: {accuracy_score(Yval, Ypred):.4f}')\n",
    "print(f'Val roc/auc: {roc_auc_score(Yval, Ypred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmmmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will it take to do better than this?\n",
    "\n",
    "Some possibilities:\n",
    "1. There are time-dependent effects that aren't captured by the inherent seasonality of the `day` predictor.\n",
    "    - May be worth exploring features constructed from recent days, or the predictors of recent days (like yesterday's `pressure`)\n",
    "2. There are meaningful non-linear interactions between predictors that may be under-represented by the tree-based feature selection of the gradient boosting classifer. \n",
    "    - Could try to explore these with EDA and feature engineering - capturing a meaningful representation could be done with NNs but could get annoying..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like I should be able to use an attention-based NN architecture to implicitly capture the temporal relationships between the predictors without needing to do any feature engineering... This would ideally address both possibilities (1) and (2) at once..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lil Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `nn.TransformerEncoderLayer` to build a small classification transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader compatible dataset\n",
    "# need len method and getitem method for compatibility with DataLoader\n",
    "class RainDataset(Dataset):\n",
    "    def __init__(self, df, seq_len: int = 7, target: str = 'rainfall'):\n",
    "        self.data = df\n",
    "        self.seq_len = seq_len\n",
    "        self.target_col = target\n",
    "        self.feat_cols = [c for c in df.columns if c != target]\n",
    "\n",
    "        self.indices = range(seq_len, len(df))  # indices for end of sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Method for pytorch DataLoader compatibility. Return feature target pairs by index (idx)\"\"\"\n",
    "        # start with end of sequence index\n",
    "        idx = self.indices[idx]\n",
    "        \n",
    "        # get indices for all observations within the sequence\n",
    "        seq_indices = range(idx - self.seq_len + 1, idx + 1)\n",
    "\n",
    "        # get featers for each observation in the sequence\n",
    "        features = torch.tensor(\n",
    "            self.data.iloc[seq_indices][self.feat_cols].values,\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # get target for END OF SEQUENCE ONLY\n",
    "        target = torch.tensor(\n",
    "            self.data.iloc[idx][self.target_col],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        return features, target\n",
    "        \n",
    "# create dataloaders\n",
    "train_ds = RainDataset(tr)\n",
    "val_ds = RainDataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaiNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_features,            # number of input features\n",
    "                 d_model=64,            # dimension of encoder layer\n",
    "                 nhead=8,               # number of heads in multiheadattention models\n",
    "                 num_encoder_layers=6,  # number of encoder layers\n",
    "                 dim_feedforward=128,   # dimension of feedforward network\n",
    "                 dropout=0.1,           # dropout rate\n",
    "                 seq_len=7              # sequence length\n",
    "                 ):\n",
    "        super(RaiNN, self).__init__()\n",
    "\n",
    "        self.wfe = nn.Linear(n_features, d_model)  # feature embedding\n",
    "        self.wpe = nn.Embedding(seq_len, d_model)  # positional embeddings\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model,\n",
    "            nhead,\n",
    "            dim_feedforward,\n",
    "            dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_encoder_layers\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1),\n",
    "            nn.Sigmoid()  # For binary classification (rainfall or not)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, sl, nf = x.size()\n",
    "        feat_emb = self.wfe(x)                       # [bs, sl, d_model]\n",
    "        pos_emb = (                                  # [bs, sl, d_model]\n",
    "            self.wpe(torch.arange(sl).to(x.device))  # positional embeddings\n",
    "            .unsqueeze(0)                            # add batch dimension\n",
    "            .repeat(bs, 1, 1)                        # repeat for number of batches\n",
    "        )\n",
    "\n",
    "        x = feat_emb + pos_emb              # [bs, sl, d_model]\n",
    "        x = self.encoder(x)                 # [bs, sl, d_model]\n",
    "\n",
    "        # we only care about predicting THE LAST DAY in the sequence\n",
    "        x = x[:, -1, :]  # get only the last element of the sequence [bs, d_model]\n",
    "\n",
    "        x = self.classifier(x)  # [bs, 1]\n",
    "        \n",
    "        return x.squeeze(1)  # [bs]\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    def train(self, train_loader, val_loader, epochs=10, lr=1e-3):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            train_loss = 0.0\n",
    "\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                y_prob = self.forward(x)\n",
    "                loss = criterion(y_prob, y)\n",
    "\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # update training loss\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # validation\n",
    "            val_loss = 0.0\n",
    "            correct = 0   # running sum of correct predictions -- for accuracy eval\n",
    "            total = 0     # running sum of total predictions -- for accuracy eval\n",
    "            with torch.no_grad():\n",
    "                for x, y in val_loader:\n",
    "\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "\n",
    "                    y_prob = self.forward(x)\n",
    "                    \n",
    "                    loss = criterion(y_prob, y)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    predicted = (y_prob > 0.5).float()\n",
    "                    total += y.size(0)\n",
    "                    correct += (predicted == y).sum().item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            accuracy = correct / total\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{epochs}')\n",
    "            print(f'Train loss: {train_loss:.4f}')\n",
    "            print(f'Val loss: {val_loss:.4f}')\n",
    "            print(f'Val acc: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train loss: 0.5787\n",
      "Val loss: 0.5340\n",
      "Val acc: 0.7935\n",
      "Epoch 2/10\n",
      "Train loss: 0.5732\n",
      "Val loss: 0.5238\n",
      "Val acc: 0.7935\n",
      "Epoch 3/10\n",
      "Train loss: 0.5711\n",
      "Val loss: 0.5182\n",
      "Val acc: 0.7935\n",
      "Epoch 4/10\n",
      "Train loss: 0.5696\n",
      "Val loss: 0.5235\n",
      "Val acc: 0.7935\n",
      "Epoch 5/10\n",
      "Train loss: 0.5758\n",
      "Val loss: 0.5217\n",
      "Val acc: 0.7935\n",
      "Epoch 6/10\n",
      "Train loss: 0.5696\n",
      "Val loss: 0.5175\n",
      "Val acc: 0.7935\n",
      "Epoch 7/10\n",
      "Train loss: 0.5700\n",
      "Val loss: 0.5183\n",
      "Val acc: 0.7935\n",
      "Epoch 8/10\n",
      "Train loss: 0.5735\n",
      "Val loss: 0.5123\n",
      "Val acc: 0.7935\n",
      "Epoch 9/10\n",
      "Train loss: 0.5717\n",
      "Val loss: 0.5158\n",
      "Val acc: 0.7935\n",
      "Epoch 10/10\n",
      "Train loss: 0.5738\n",
      "Val loss: 0.5172\n",
      "Val acc: 0.7935\n"
     ]
    }
   ],
   "source": [
    "model = RaiNN(n_features=tr.shape[1] - 1, seq_len=30)\n",
    "model.train(train_loader, val_loader, epochs=10, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benak\\Python_Base_Dir\\data_science\\data_science\\kaggle\\playground\\rain_nn.py:40: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_e1nmgx0bk6\\croot\\pytorch-select_1725478824526\\work\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  features = torch.tensor([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5796, Val Loss: 0.5070, Accuracy: 0.7935\n",
      "Epoch 2/10, Train Loss: 0.5713, Val Loss: 0.5336, Accuracy: 0.7935\n",
      "Epoch 3/10, Train Loss: 0.5711, Val Loss: 0.5153, Accuracy: 0.7935\n",
      "Epoch 4/10, Train Loss: 0.5705, Val Loss: 0.5135, Accuracy: 0.7935\n",
      "Epoch 5/10, Train Loss: 0.5751, Val Loss: 0.5072, Accuracy: 0.7935\n",
      "Epoch 6/10, Train Loss: 0.5731, Val Loss: 0.5134, Accuracy: 0.7935\n",
      "Epoch 7/10, Train Loss: 0.5708, Val Loss: 0.5133, Accuracy: 0.7935\n",
      "Epoch 8/10, Train Loss: 0.5742, Val Loss: 0.5137, Accuracy: 0.7935\n",
      "Epoch 9/10, Train Loss: 0.5715, Val Loss: 0.5228, Accuracy: 0.7935\n",
      "Epoch 10/10, Train Loss: 0.5732, Val Loss: 0.5112, Accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "import rain_nn as rainn\n",
    "dl_tr = DataLoader(rainn.WeatherDataset(tr), batch_size=32, shuffle=True)\n",
    "dl_val = DataLoader(rainn.WeatherDataset(val), batch_size=32, shuffle=True)\n",
    "\n",
    "model = rainn.WeatherTransformer(num_features=tr.shape[1] - 1)\n",
    "trained_model = rainn.train_model(model, dl_tr, dl_val, num_epochs=10, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, t = next(val_loader.__iter__())\n",
    "t.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features, sample_target = next(iter(val_loader))\n",
    "sample_features = sample_features[0].unsqueeze(0)  # Add batch dimension\n",
    "prediction = model(sample_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = (prediction > 0.5).float()\n",
    "(predicted == t).sum().item() / t.size(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
