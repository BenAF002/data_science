{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Systems of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's represent the general form for a system of linear equations:\n",
    "$$a_{11}x_1 + \\cdots + a_{1n}x_n = b_1 \\\\ \\vdots \\\\ a_{m1x_1} + \\cdots + a_{mn}x_n = b_m \\\\ \\ \\\\ \\equiv \\mathbf{A}\\mathbf{x} = \\mathbf{b}$$\n",
    "Where $\\mathbf{A}, \\mathbf{x}, \\mathbf{b} \\in \\reals^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $n$-tuple $(x_1, ..., x_n) \\in \\reals$ that satisfies all of these equations simultaneously is the *solution* of the linear equation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elementwise multiplication of matrices is called the ***Hadamard Product***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some properties of matrix multiplication (*dot products*) and addition:\n",
    "- ***Associativity:***\n",
    "$$\\forall \\mathbf{A} \\in \\reals^{m\\times n}, \\mathbf{B} \\in \\reals^{n\\times p}, \\mathbf{C} \\in \\reals^{p\\times q}: \\ (\\mathbf{A}\\mathbf{B})\\mathbf{C} = \\mathbf{A}(\\mathbf{B}\\mathbf{C})$$\n",
    "- ***Distributivity:***\n",
    "$$\\forall \\mathbf{A}, \\mathbf{B} \\in \\reals^{m\\times n}, \\mathbf{C}, \\mathbf{D} \\in \\reals^{n\\times p}: \\ (\\mathbf{A} + \\mathbf{B})\\mathbf{C} = \\mathbf{A}\\mathbf{C} + \\mathbf{B}\\mathbf{C} \\ ; \\ \\ \\mathbf{A}(\\mathbf{C} + \\mathbf{D}) = \\mathbf{A}\\mathbf{C} + \\mathbf{A}\\mathbf{D} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse and Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Inverse:**\n",
    "- For a square matrix $\\mathbf{A} \\in \\reals^{n\\times n}$, $\\mathbf{A}^{-1}$ is its *inverse* if and only if $\\mathbf{A}^{-1}$ has the property that: $$\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}_n = \\mathbf{A}^{-1}\\mathbf{A}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix may be thought of as a series of transformations applied to a vector or set of vectors (like those comprising a space). The inverse is then just the set of reverse transformations. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3]\n",
      " [-3  0]\n",
      " [ 3  3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rotate = np.array([[0, -1], [1, 0]])  # rotate by 90-degrees\n",
    "shear = np.array([[0, 1], [1, 1]])   # applye a 45-degree shear\n",
    "\n",
    "origin = np.array([[0, 0, 0],[0, 0, 0]]) # origin point\n",
    "\n",
    "v =  np.array([0, 3])  # original vector\n",
    "\n",
    "V = np.array([v, rotate @ v, shear @ v])\n",
    "\n",
    "print(V)\n",
    "\n",
    "plt.quiver(\n",
    "    *origin, # unpack origin coordinates\n",
    "    V[:, 0], # x-direction\n",
    "    V[:, 1], # y-direction\n",
    "    color = ['blue', 'orange', 'cyan'],\n",
    "    scale = 20\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orange arrow represents the original vector $\\mathbf{v}$. The blue arrow is the result of a 90-degree rotation, $\\mathbf{R}$ applied to the $\\mathbf{v}$. The cyan arrow is the result of a shear, $\\mathbf{S}$ applied to $\\mathbf{v}$. Written out, these transformations are respectively:\n",
    "$$\\begin{bmatrix} 0 \\ -1 \\\\ 1 \\ \\ \\ \\ \\ 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} -3 \\\\ 0 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 0 \\ \\ 1 \\\\ 1 \\ \\ 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix}$$\n",
    "\n",
    "Both of these transformations are reversible. We may use the inverses $\\mathbf{R}^{-1}$ and $\\mathbf{S}^{-1}$ to the transformed vector to yield the original vector. In this case, the inverses are:\n",
    "$$\\begin{bmatrix} 0 \\ \\ \\ \\ 1 \\\\ -1 \\ \\ 0 \\end{bmatrix} \\begin{bmatrix} -3 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix}$$\n",
    "And similarly:\n",
    "$$\\begin{bmatrix} -1 \\ \\ \\ \\ 1 \\\\ 1 \\ \\ 0 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.],\n",
       "        [-1., -0.]]),\n",
       " array([[-1.,  1.],\n",
       "        [ 1.,  0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(rotate), np.linalg.inv(shear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how can we know that these are the appropriate inverses? Afterall, we can easily find other transformations that equivalently return the original vector $\\mathbf{v}$. Well, there's a process outlined in the next section..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not every matrix is invertible. An invertible matrix is called ***regular/invertible/nonsingular*** while a non-invertible matrix is called ***singular/noninvertible***. Furthermore, a matrix must be square to be invertible. \n",
    "\n",
    "Let's expand on this square matrices thing. A non-square matrix has either more rows than columns or more columns than rows. Consider an $(m \\times n)$ matrix $\\mathbf{A}$ with $m > n$ that transforms a $(n \\times 1)$ column vector $\\mathbf{v}$. The result of which, $\\mathbf{A}\\mathbf{v} = \\mathbf{b}$ is an $(m \\times 1)$ column vector. Because $m > n$, we cannot determine a *unique* transformation to convert $\\mathbf{b}$ back into $\\mathbf{v}$. The tranformation applied by $\\mathbf{A}$ has projected $\\mathbf{v}$ into a higher dimensional space. Specifically, it has increased the column space of the vector. \n",
    "\n",
    "Working in the opposite direction, with $m < n$, we *canot* identify *any* transformation that will yield the original vector because the resulting vector $\\mathbf{b}$ spans a lower dimensional space than the original vector $\\mathbf{v}$. So, we simply do not have enough information to reverse the transformation. Now, there is a caveat to this: There may exist inverses when the result of the transformation lies on the span of the original vector. E.g., when the resulting vector lies on the plane spanned by the original vector...\n",
    "\n",
    "These cases have special names: \n",
    "- When a matrix has more rows than columns, $m > n$, it is said to be ***over-determined***. \n",
    "- When a matrix has more columns than rows, $m < n$, it is said to be ***under-determined***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Transpose:**\n",
    "- For $\\mathbf{A} \\in \\reals^{m\\times n}$ the matrix $\\mathbf{B} \\in \\reals^{n\\times m}$ with $b_{ij} = a_{ji}$ is the transpose of $\\mathbf{A}$. It is denoted $\\mathbf{A}^\\intercal$\n",
    "\n",
    "In general, the transpose of a matrix may be obtained by writing its columns as rows and its rows as columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Properties of Inverses and Transposes\n",
    "$$\n",
    "(\\mathbf{A} \\mathbf{B})^{-1} = \\mathbf{B}^{-1}\\mathbf{A}^{-1} \\\\\n",
    "(\\mathbf{A} + \\mathbf{B})^{-1} \\ne \\mathbf{A}^{-1} + \\mathbf{B}^{-1} \\\\\n",
    "\\ \\\\\n",
    "(\\mathbf{A}\\mathbf{B})^\\intercal = \\mathbf{B}^\\intercal \\mathbf{A}^\\intercal \\\\\n",
    "(\\mathbf{A} + \\mathbf{B})^\\intercal = \\mathbf{A}^\\intercal + \\mathbf{B}^\\intercal\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Symmetric Matrix:**\n",
    "- A matrix $\\mathbf{A} \\in \\reals^{n\\times n}$ is symmetric if $\\mathbf{A} = \\mathbf{A}^\\intercal$\n",
    "\n",
    "Note that the sum of symmetric matrices is always symmetric, but their products need not be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementary Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementary transformations help to solve systems of linear equations by keeping the solution set *the same*, but transforming the equation system into a simpler form. The basic elementary operations are as follows:\n",
    "- Exchange of two equations (i.e. rows in the matrix)\n",
    "- Multiplication of an equation (row) by a constant $\\lambda \\in \\reals$\n",
    "- Addition of two equations (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to skip over most of this. Although knowing what row-echelon form and Gaussian elimination are is valuable, I don't really care about the algorithmic processes of elementary transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Row-Echelon Form:**\n",
    "- A matrix is in row-echelon form if:\n",
    "    - All rows that contain only zeros are at the bottom of the matrix\n",
    "    - The first nonzero number from the left (also called the *pivot* or the *leading coefficient*) of each nonzero row is always strictly to the right of the pivot of the row above it\n",
    "- The variables corresponding to the pivots in a row-echelon form matrix are called the *basic variables* and the other variables are called the *free variables*\n",
    "- E.g. $$\\begin{bmatrix} 2 \\ \\ 0 \\ \\ 6 \\ \\ 9 \\\\ 0 \\ \\ 1 \\ \\ 3 \\ \\ 2 \\\\ 0 \\ \\ 0 \\ \\ 4 \\ \\ 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Reduced-Row-Echelon Form:**\n",
    "- A matrix is in RREF if\"\n",
    "    - It is in row-echelon form (REF)\n",
    "    - Every pivot is $1$\n",
    "    - The pivot is the only nonzero entry in its *column*\n",
    "- E.g. $$\\begin{bmatrix} 1 \\ \\ 0 \\ \\ 0 \\ \\ 9 \\\\ 0 \\ \\ 1 \\ \\ 0 \\ \\ 2 \\\\ 0 \\ \\ 0 \\ \\ 1 \\ \\ 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Elimination:**\n",
    "- Gaussian elimination is an algorithm that performs elementary row transformations to bring a system of linear equations into RREF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Vector Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ***Group*** is a set of elements *and* an operation defined on these elements that keeps some structure of the set intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Group:**\n",
    "- Consider a set $\\mathcal{G}$ and an operation $\\otimes : \\mathcal{G} \\times \\mathcal{G} \\rightarrow \\mathcal{G}$ defined on $\\mathcal{G}$. Then $G \\coloneqq ( \\mathcal{G}, \\otimes )$ is called a *group* if the following hold:\n",
    "    1. ***Closure*** of $\\mathcal{G}$ under $\\otimes$\n",
    "        - $\\forall \\ x, y \\ \\in \\mathcal{G} \\ : \\ x \\otimes y \\in \\mathcal{G}$\n",
    "    2. ***Associativity***\n",
    "        - $\\forall \\ x, y, z \\ \\in \\mathcal{G} \\ : \\ (x \\otimes y ) \\otimes z = x \\otimes (y \\otimes z )$\n",
    "    3. ***Neutral Element***\n",
    "        - $\\exists e \\in \\mathcal{G} \\ \\forall x \\in \\mathcal{G} \\ : \\ x \\otimes e = x \\ \\ \\text{and} \\ \\ e \\otimes x = x$\n",
    "    4. ***Inverse Element***\n",
    "        - $\\forall x \\in \\mathcal{G} \\ \\exists y \\in \\mathcal{G} \\ : \\ x \\otimes y = e \\ \\ \\text{and} \\ \\ y \\otimes x = e$\n",
    "            - Where $e$ is the neutral element.\n",
    "            - The inverse element is typically denoted $x^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the additional characteristic of *commutativity* holds, then the group is an ***Abelian Group***.\n",
    "- ***Commutative***\n",
    "    - $\\forall x, y \\in \\mathcal{G} \\ : \\ x \\otimes y = y \\otimes x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of General Linear Group**\n",
    "- The set of invertible matrices $\\mathbf{A} \\in \\reals^{n \\times n}$ is a group w.r.t. the matrix multiplication operation and is called the general linear group. It is denoted $GL(n, \\reals)$\n",
    "    - Note that because matrix multiplication is *not commutative*, the general linear group *is not* and Abelian group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Vector Space:**\n",
    "- A real-valued vector space $V = (\\mathcal{V}, +, \\cdot)$ is a set $\\mathcal{V}$ with *two* operations: $$ + \\ : \\ \\mathcal{V} \\times \\mathcal{V} \\rightarrow \\mathcal{V} \\\\ \\cdot \\ : \\ \\reals \\times \\mathcal{V} \\rightarrow \\mathcal{V}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first operations, $+$, is vector addition and is an inner operation; that is, it only operates on elements already in the set $\\mathcal{V}$. The operation $\\cdot$ is an *outer* operation; that is, it need not operate only on elements of the set, but on any element in $\\reals$.\n",
    "\n",
    "Vector spaces satisfy the following properties:\n",
    "1. $(\\mathcal{V}, +)$ is an Abelian group\n",
    "2. ***Distributivity***\n",
    "    1. $\\forall \\lambda \\in \\reals; \\ \\mathbf{x}, \\mathbf{y} \\in \\mathcal{V} \\ : \\ \\lambda \\cdot (\\mathbf{x} + \\mathbf{y}) = \\lambda \\cdot \\mathbf{x} + \\lambda \\cdot \\mathbf{y}$\n",
    "    2. $\\forall \\lambda, \\psi \\in \\reals; \\ \\mathbf{x} \\in \\mathcal{V} \\ : \\ (\\lambda + \\psi) \\cdot \\mathbf{x} = \\lambda \\cdot \\mathbf{x} + \\psi \\cdot \\mathbf{x}$\n",
    "3. ***Associativity*** (of the outer operation $\\cdot$)\n",
    "    - $\\forall \\lambda, \\psi \\in \\reals; \\ \\mathbf{x} \\in \\mathcal{V} \\ : \\ \\lambda \\cdot (\\psi \\cdot \\mathbf{x}) = (\\lambda \\psi) \\cdot \\mathbf{x}$\n",
    "4. ***Neutral Element*** (of the outer operation $\\cdot$)\n",
    "    - $\\forall \\mathbf{x} \\in \\mathcal{V} \\ : \\ 1 \\cdot \\mathbf{x} = \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outer operation $\\cdot$ corresponds to a form of scaling, such as scalar multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much more rigorous definition of vector spaces than the descriptive definition given when learning the geometric intuition of linear algebra. However, this definition is consistent with the geometric interpretation and any meaningful characteristics of the geometric interpretation are extendable to this well defined interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Vector Subspace:**\n",
    "- Let $V = (\\mathcal{V}, +, \\cdot)$ be a vector space and $\\mathcal{U} \\subseteq \\mathcal{V}$ (note that this denotes $\\mathcal{U}$ as a subset of $\\mathcal{V}$). Then $U=(\\mathcal{U}, +, \\cdot)$ is a *vector subspace* of $V$ if $U$ is also a vector space. We denote this subsapace as $U \\subseteq V$.\n",
    "\n",
    "A vector subspace $U$ naturally inherits many properties directly from $V$ because any properties that hold for all $\\mathbf{x} \\in \\mathcal{V}$ also holds for all $\\mathbf{x} \\in \\mathcal{U} \\subseteq \\mathcal{V}$.\n",
    "\n",
    "To determine whether $U$ is a subspace of $V$, we need to show that:\n",
    "1. $\\mathcal{U} \\ne \\empty$; in particular: $\\mathbf{0} \\in \\mathcal{U}$\n",
    "2. Closure of $U$:\\\n",
    "    a. W.r.t. the outer operation: $\\forall \\lambda \\in \\reals, \\ \\forall \\mathbf{x} \\in \\mathcal{U} \\ : \\ \\lambda \\mathbf{x} \\in \\mathcal{U}$\\\n",
    "    b. W.r.t. the inner operation: $\\forall \\mathbf{x}, \\mathbf{y} \\in \\mathcal{U} \\ : \\ \\mathbf{x} + \\mathbf{y} \\in \\mathcal{U}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "- Not all *subsets* of $\\reals^n$ are *subspaces* of $\\reals^n$\n",
    "    - We may easily find subsets of $\\reals^n$ for which closure is violated or for which $\\mathbf{0}$ is not an element.\n",
    "    - E.g. the cartesian reals $(x,y) \\in \\reals^2$. The line $y = x - 2$ is a subset of $\\reals^2$ but it is not a subspace of $\\reals^2$ because it does not contain $[0, 0]^\\intercal$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Linear Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basis**\n",
    "- The set of vectors from which we can represent *every other* vector in a vector space by adding them together and/or scaling them.\n",
    "- Vector spaces may have many sets of basis vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Linear Combination**\n",
    "- For a vector space $V$ and a set of vectors $\\mathbf{x}_1, ..., \\mathbf{x}_k \\in V$, every $\\mathbf{v} \\in V$ of the form $$\\mathbf{v} = \\lambda_1 \\mathbf{x}_1 + \\cdots + \\lambda_k \\mathbf{x}_k = \\sum_{i=1}^k \\lambda_i \\mathbf{x}_i \\in V$$ is a *linear combination* of the vectors $\\mathbf{x}_1, ..., \\mathbf{x}_k$. Where $\\lambda_1, ..., \\lambda_k \\in \\reals$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Linear Dependence**\n",
    "- For a vector space $V$, the vectors $\\mathbf{x}_1, ..., \\mathbf{x}_k \\in V$ are *linearly dependent* if there is a *non-trivial* linear combination such that $\\sum_{i=1}^k \\lambda_i \\mathbf{x}_i = \\mathbf{0}$ with at least one $\\lambda_i \\ne 0$.\n",
    "    - The contrapositive holds; i.e., if only the trivial solution exists then the vectors are *linearly independent*\n",
    "\n",
    "A key result of linear dependence is that vectors within the set of linearly dependent vectors are equal to some linear combination of the other vectors in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Basis and Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Generating Set and Span:**\n",
    "- For a vector space $V$ and set of vectors $\\mathcal{A} = {\\mathbf{x}_1, ..., \\mathbf{x}_k} \\subseteq \\mathcal{V}$, $\\mathcal{A}$ is ***Generating Set*** of $V$ if every vector $\\mathbf{v} \\in \\mathcal{V}$ can be expressed as a linear combination of the vectors ${\\mathbf{x}_1, ..., \\mathbf{x}_k} \\in \\mathcal{A}$\n",
    "- The set of all linear combinations of vectors in a set of vectors, $\\mathcal{A}$, is called the ***Span*** of $\\mathcal{A}$\n",
    "    - If $\\mathcal{A}$ spans the vector space $V$ (as it does if it is a generating set), then we write $V = \\text{span}[\\mathcal{A}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Rank:**\n",
    "- The number of linearly independent columns of a matrix $\\mathbf{A} \\in \\real^{m \\times n}$ is *necessarily equal to* the number of linearly independent rows. This number is called the ***Rank*** of $\\mathbf{A}$ and is denoted $\\text{rk} (\\mathbf{A})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important properties of rank:\n",
    "- The columns of $\\mathbf{A} \\in \\real^{m \\times n}$ span a subspace $U \\subseteq \\reals^m$ with $\\text{dim}(U) = \\text{rk}(\\mathbf{A})$\n",
    "- The rows of $\\mathbf{A} \\in \\real^{m \\times n}$ span a subspace $W \\subseteq \\reals^n$ with $\\text{dim}(W) = \\text{rk}(\\mathbf{A})$\n",
    "- For all $\\mathbf{A} \\in \\reals^{n \\times n}$ it holds that $\\mathbf{A}$ is invertible if and only if $\\text{rk}(\\mathbf{A}) = n$\n",
    "- A matrix $\\mathbf{A} \\in \\reals^{m \\times n}$ has ***Full Rank*** if its rank equals the largest possible rank for a matrix of the same dimensions. This means that its rank is the lesser of its number of rows or columns; i.e., $\\text{rk}(A) = \\min(m, n)$\n",
    "    - A matrix that does not have full rank is called ***Rank Deficient***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Basis:**\n",
    "- A generating set $\\mathcal{A}$ of a vector space $V$ is called *minimal* if there exists no smaller set that spans $V$. Every *linearly independent* generating set of $V$ that is minimal is called a ***Basis*** of $V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Linear Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two real vector spaces $V,W$, we denote a mapping as: $$\\Phi : \\ V \\rightarrow W$$\n",
    "A mapping will preserve the structure of the vector space (i.e., ensure the result is also a vector space) if:\n",
    "$$\\Phi (\\mathbf{x} + \\mathbf{y}) = \\Phi(\\mathbf{x}) + \\Phi(\\mathbf{y}) \\\\ \\Phi(\\lambda \\mathbf{x}) = \\lambda \\Phi(\\mathbf{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Linear Mapping:**\n",
    "- For vector spaces $V, W$, a mapping $\\Phi: \\ V \\rightarrow W$ is called a *linear mapping* if:\n",
    "$$\\forall \\mathbf{x}, \\mathbf{y} \\in V \\ \\forall \\lambda, \\psi \\in \\reals \\ : \\ \\Phi(\\lambda\\mathbf{x} + \\psi\\mathbf{y}) = \\lambda\\Phi(\\mathbf{x}) + \\psi\\Phi(\\mathbf{y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear mappings may also be called *vector space homomorphisms* or ***Linear Transformations*** (much more familiar term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special Mappings:**\\\n",
    "For a mapping $\\Phi: \\ \\mathcal{V} \\rightarrow \\mathcal{W}$:\n",
    "- ***Injective*** if:\n",
    "$$ \\forall \\mathbf{x}, \\mathbf{y} \\in \\mathcal{V} \\ : \\ \\Phi(\\mathbf{x}) = \\Phi(\\mathbf{y}) \\implies \\mathbf{x} = \\mathbf{y}$$\n",
    "- ***Surjective*** if:\n",
    "$$\\Phi(\\mathcal{V}) = \\mathcal{W}$$\n",
    "- ***Bijective*** if the mapping is both injective *and* surjective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on surjective mappings:\\\n",
    " If $\\Phi$ is surjective, then every element in $\\mathcal{W}$ can be \"reached\" from $\\mathcal{V}$ using $\\Phi$. This seems self explanatory from the denotation of a mapping. However, we need to note that the mapping $\\Phi : \\ \\mathcal{V} \\rightarrow \\mathcal{W}$ itself does not imply that the set $\\mathcal{V}$ maps to the *entirety* of the set $\\mathcal{W}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on bijective mappings:\\\n",
    "A bijective mapping $\\Phi$ can be reversed. That is, there exists a mapping $\\Psi: \\ \\mathcal{W} \\rightarrow \\mathcal{V}$ such that $\\Psi \\big( \\Phi(v\\mathbf{x}) \\big) = \\mathbf{x}$. This mapping $\\Psi$ is the inverse of $\\Phi$ and is denoted $\\phi^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More mapping names:\n",
    "- ***Isomorphism:*** $\\Phi: V \\rightarrow W$ is linear and bijective\n",
    "- ***Endomorphism:*** $\\Phi: V \\rightarrow V$ is linear\n",
    "- ***Automorphism:*** $\\Phi: V \\rightarrow V$ is linear and bijective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem (2.17):**\n",
    "- Finite-dimensional vector spaces $V$ and $W$ are *isomorphic* if and only if $\\text{dim}(V) = \\text{dim}(W)$\n",
    "\n",
    "In words, this theorem states that there exists a linear, bijective mapping between any two vector spaces of the same dimension. This means that vector spaces of the same dimension are effectively the same because they may be transformed into each other without any loss. This seems tautological because what other difference between vector spaces can exist besides their dimensions? A difference in basis? But that isn't part of the definition of a vector space... This theorem does correspond to the understanding of the concept of change of basis...\n",
    "\n",
    "This theorem also formalizes a justification for treating the vector space of $m \\times n$ matrices, $\\reals^{m \\times n}$, and the vector space of length $mn$ vectors, $\\reals^{mn}$, as the same - because they have the same $\\text{dim}()$, and thus there exists a linear, bijective mapping between the two. This treatment is functionally very useful in modeling. It makes sense following the logic of the formalized definitions of spaces and transformations, but I don't see a geometric intuition for it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Representation of Linear Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By theorem 2.17, any $n$ dimensional vector space is isomorphic to any other vector space in $\\reals^n$. So, we can switch between the bases of any vector space in $\\reals^n$ without losing any information. Let's denote the basis of vector space $V$ as: $$B = (\\mathbf{b}_1, ..., \\mathbf{b}_n)$$ \n",
    "We denote $B$ as a *tuple* of basis vectors instead of as a set because we care about the *order* of the basis vectors in $B$. Thus, $B$ is called an ***Ordered Basis*** of $V$.\n",
    "\n",
    "**Definition of Coordinates:**\n",
    "- For a vector space $V$ with an ordered basis $B$, for any $\\mathbf{x} \\in V$ we may obtain a unique representation (i.e. a linear combination) of $\\mathbf{x}$ w.r.t. $B$. $$\\mathbf{x} = \\alpha_1\\mathbf{b}_1 + \\cdots + \\alpha_n \\mathbf{b}_n$$\n",
    "Then the coefficients $\\alpha_1, ..., \\alpha_n$ are the ***Coordinates*** of $\\mathbf{x}$ w.r.t. $B$, and the vector $\\mathbf{\\alpha} \\in \\reals^n$ is the *coordinate vector / coordinate representation* of $\\mathbf{x}$ w.r.t. the ordered basis $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cartesian coordinate system this definition of coordinates is made very clear. Any point on the cartesian plane may be represented as a vector from the origin, e.g. the point $(2, 5)$ may be written as the vector $[2, 5]^\\intercal$. With ***Canonical Basis Vectors*** $\\mathbf{e}_1 = [1, 0]^\\intercal$ and $\\mathbf{e}_2 = [0, 1]^\\intercal$, this point (which we already think of as a coordinate) may be expressed as a coordinate $(\\alpha_1 = 2, \\alpha_2 = 5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in effect, a basis *defines* a coordinate system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Transformation Matrix:**\n",
    "- Let $V$ be a vector space with $n$ ordered bases $B$ and $W$ be a vector space with $m$ ordered bases $C$. For a linear mapping $\\Phi: V \\rightarrow W$: $$\\Phi(\\mathbf{b}_j) = \\alpha_{1j}\\mathbf{c}_1 + \\cdots + \\alpha_{mj} \\mathbf{c}_m = \\sum_{i=1}^m \\alpha_{ij} \\mathbf{c}_i$$\n",
    "This is the unique representation of $\\Phi(\\mathbf{b}_j)$ w.r.t. $C$.\\\n",
    "Then, we call the $m \\times n$ matrix $\\mathbf{A}_\\Phi$ with elements given by $\\mathbf{A}_\\Phi(i,j) = \\alpha_{ij}$ the ***Transformation Matrix*** of $\\Phi$.\n",
    "\n",
    "Note that the elements of the $j$-th column of $\\mathbf{A}_\\Phi$ are the *coordinates* of $\\Phi(\\mathbf{b}_j)$ w.r.t. the ordered basis $C$ of $W$.\n",
    "\n",
    "The transformation matrix effectively maps coordinates w.r.t. the ordered basis in one vector space to the coordinates w.r.t. the ordered basis in another vector space.\\\n",
    "I think some examples may be good here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $\\Phi: V \\rightarrow W$ with ordered bases $B=(\\mathbf{b}_1, \\mathbf{b}_2, \\mathbf{b}_3)$ of $V$ and $C=(\\mathbf{c}_1, \\mathbf{c}_2, \\mathbf{c}_3, \\mathbf{c}_4)$ of $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranformation matrix: \n",
      " [[ 1  2  0]\n",
      " [-1  1  3]\n",
      " [ 3  7  1]\n",
      " [-1  2  4]]\n"
     ]
    }
   ],
   "source": [
    "# phi_b1 = c1 - c2 + 3*c3 - c4\n",
    "# phi_b2 = 2*c1 + c2 + 7*c3 + 2*c4\n",
    "# phi_b3 = 3*c2 + c3 + 4*c4\n",
    "A = np.array([\n",
    "        [1, -1, 3, -1], # phi_b1\n",
    "        [2, 1, 7, 2],   # phi_b2\n",
    "        [0, 3, 1, 4]    # phi_b3\n",
    "    ]).T\n",
    "print(\"Tranformation matrix: \\n\", A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may choose to change the bases of a vector space - this can facilitate easier transformations.\\\n",
    "Take vector spaces $V$ and $W$ with ordered bases $B$ and $\\tilde{B}$ in $V$ of length $n$ and ordered bases $C$ and $\\tilde{C}$ in $W$ of length $m$. Then the transfomation matrix for the mapping $\\Phi: V \\rightarrow W$ may be represented as $\\mathbf{A}_\\Phi$ or $\\mathbf{\\tilde{A}}_\\Phi$.\n",
    "\n",
    "Example:\n",
    "$$\\mathbf{A} = \\begin{bmatrix} 2 \\ \\ 1 \\\\ 1 \\ \\ 2 \\end{bmatrix}$$ \n",
    "$\\mathbf{A}$ is a transformation matrix w.r.t. the canonical basis in $\\reals^2$.\\\n",
    "However, we may define a new basis for the same space: $$\\mathbf{B} = \\begin{bmatrix} 1 \\ \\ \\ \\ 1 \\\\ 1  -1 \\end{bmatrix}$$\n",
    "The transformation matrix w.r.t. this new basis $\\mathbf{B}$ is:\n",
    "$$\\mathbf{\\tilde{A}} = \\begin{bmatrix} 3 \\ \\ 0 \\\\ 0 \\ \\ 1 \\end{bmatrix}$$\n",
    "This new diagonal transformation matrix $\\mathbf{\\tilde{A}}$ w.r.t. $\\mathbf{B}$ is easier to work with than $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem (2.20):**\n",
    "- For a linear mapping $\\Phi: V \\rightarrow W$ and the ordered bases (of $V$ and $W$ respectively): $$ B= (\\mathbf{b}_1, ..., \\mathbf{b}_n), \\ \\ \\ \\tilde{B} = (\\mathbf{\\tilde{b}}_1, ..., \\mathbf{\\tilde{b}}_n) \\\\ \\ \\\\ C = (\\mathbf{c}_1, ..., \\mathbf{c}_m), \\ \\ \\ \\tilde{C} = (\\mathbf{\\tilde{c}}_1, ..., \\mathbf{\\tilde{c}}_m)$$ \n",
    "Then, $$\\mathbf{\\tilde{A}}_\\Phi = \\mathbf{T}^{-1}\\mathbf{A}_\\Phi \\mathbf{S}$$\n",
    "Where, $\\mathbf{A}_\\Phi$ is the transformation matrix of $\\Phi$ w.r.t $B$ and $C$ and $\\mathbf{\\tilde{A}}_\\Phi$ is the transformation matrix of $\\Phi$ w.r.t. $\\tilde{B}$ and $\\tilde{C}$.\\\n",
    " The matrix $\\mathbf{S} \\in \\reals^{n \\times n}$ is the transformation matrix of $V$ that maps coordinates w.r.t. $\\tilde{B}$ onto coordinates w.r.t. $B$. The matrix $\\mathbf{T} \\in \\reals^{m \\times m}$ is the transformation matrix that maps coordinates w.r.t. $\\tilde{C}$ onto coordinates w.r.t. $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot of writing, but it's actually quite straightforward. Let's take a coordinate vector $\\mathbf{x} \\in V$ w.r.t $B$. Then expressing this coordinate vector w.r.t. $\\tilde{B}$ is:\n",
    "$$\\mathbf{\\tilde{x}} = \\mathbf{S}^{-1}\\mathbf{x}$$\n",
    "Then we may map $\\mathbf{\\tilde{x}}$ to coordinates $\\mathbf{\\tilde{y}}$ w.r.t. the basis $\\tilde{C}$ as:\n",
    "$$\\mathbf{\\tilde{y}} = \\mathbf{\\tilde{A}}_\\Phi \\mathbf{\\tilde{x}} = \\mathbf{\\tilde{A}}_\\Phi \\mathbf{S}^{-1} \\mathbf{x}$$\n",
    "Finally, we may map the coordinate $\\mathbf{\\tilde{y}}$ w.r.t. the basis $\\tilde{C}$ to the coordinate $\\mathbf{y}$ w.r.t. the basis $C$ as:\n",
    "$$\\mathbf{y} = \\mathbf{T}\\mathbf{\\tilde{A}}_\\Phi\\mathbf{\\tilde{x}} = \\mathbf{T}\\mathbf{\\tilde{A}}_\\Phi \\mathbf{S}^{-1}\\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, $$\\mathbf{y} = \\mathbf{A}_\\Phi \\mathbf{x} = \\mathbf{T}\\mathbf{\\tilde{A}}_\\Phi \\mathbf{S}^{-1}\\mathbf{x}$$\n",
    "And, $$\\mathbf{\\tilde{y}} = \\mathbf{\\tilde{A}}_\\Phi \\mathbf{\\tilde{x}} = \\mathbf{T}^{-1}\\mathbf{A}_\\Phi \\mathbf{S}\\mathbf{\\tilde{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{S}$ and $\\mathbf{T}$ are ***Identity Mappings*** - they map vectors *onto themselves* but with respect to different basises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Equivalence:**\n",
    "- Two matrices $\\mathbf{A}, \\mathbf{\\tilde{A}} \\in \\reals^{m \\times n}$ are equivalent if there exist regular matrices $\\mathbf{S}$ and $\\mathbf{T}$ such that $\\mathbf{\\tilde{A}} = \\mathbf{T}^{-1} \\mathbf{A} \\mathbf{S}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of Similarity:**\n",
    "- Two matrices $\\mathbf{A}, \\mathbf{\\tilde{A}} \\in \\reals^{n \\times n}$ are *similar* if there exists a regular matrix $\\mathbf{S} \\in \\reals^{n \\times n}$ with $\\mathbf{\\tilde{A}} = \\mathbf{S}^{-1}\\mathbf{A}\\mathbf{S}$ \n",
    "\n",
    "Similar matrices are always equivalent, but not all equivalent matrices are similar. This should be plain to see from the definitions: equivalence can hold for matrices of any shape, $\\reals^{m \\times n}$, while similarity can only hold for square matrices, $\\reals^{n \\times n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image and Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image and kernel of a linear mapping are vector subspaces with important properties.\n",
    "\n",
    "**Definition of Image and Kernel:**\n",
    "- For a mapping $\\Phi: V \\rightarrow W$, the ***Kernel*** or ***Null Space*** is: $$ker(\\Phi) \\coloneqq \\Phi^{-1}(\\mathbf{0}_W) = \\{\\mathcal{v} \\in V : \\Phi(\\mathcal{v}) = \\mathbf{0}_W\\}$$\n",
    "- The ***Image*** or ***Range*** is:\n",
    "$$\\text{Im}(\\Phi) \\coloneqq \\Phi(V) = \\{\\mathcal{w} \\in W | \\exists\\mathcal{v} \\in V: \\Phi(\\mathcal{v}) = \\mathcal{w}\\}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written out:\n",
    "- The kernel is the set of vectors $\\mathcal{v} \\in V$ that $\\Phi$ maps onto the null vector $\\mathcal{0}_W \\in W$\n",
    "    - The null space is the space spanned by these $\\mathcal{v}$ vectors\n",
    "- The image is the set of vectors $\\mathcal{w} \\in W$ that can be reached by any vector in $V$ through the mapping $\\Phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a linear transformation $\\mathbf{A} \\in \\reals^{m \\times n}$ of a linear mapping $\\Phi:\\reals^n \\rightarrow \\reals^m$, the image can be obtained as:\n",
    "$$\\text{Im}(\\Phi) = {\\mathbf{A}\\mathbf{x}:\\mathbf{x} \\in \\reals^n} = \\text{span}[\\mathbf{a}_1, ..., \\mathbf{a}_n] \\subseteq \\reals^m$$\n",
    "- That is, the image of the mapping is the ***Column Space*** of $\\mathbf{A}$ (i.e. the span of its columns)\n",
    "    - This is intuitive from the definition of the image. The set of all reachable vectors in the subspace resulting from a transformation is necessarily the span of the transformation\n",
    "        - The geometric intuition for it being the span of the columns (rather than of the rows) follows from viewing the matrix as a collection of column vectors; each applying a transformation in sequence\n",
    "- $\\text{rk}(\\mathbf{A}) = \\dim(\\text{Im}(\\Phi))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel/null space is the general solution to the homogeneous system of linear equations $\\mathbf{A}\\mathbf{x} = \\mathbf{0}$.\n",
    "- It captures all elements in $\\reals^n$ that produce $\\mathbf{0} \\in \\reals^m$\n",
    "- It is a subspace of $\\reals^n$\n",
    "    - This stems from it being a solution to the homogeneous system of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.24 - Rank-Nullity Theorem:**\n",
    "- For vector spaces $V, W$ and a linear mapping $\\Phi: V \\rightarrow W$, it holds that:\n",
    "$$\\dim(\\ker(\\Phi)) + \\dim(\\text{Im}(\\Phi)) = \\dim(V)$$\n",
    "This is broadly intuitive if we consider the results of a linear mapping $\\Phi: V \\rightarrow W$. Either, we get to some vector in $W$, which is then of the set $\\mathcal{w} \\in W$ which comprises that image $\\text{Im}(\\Phi)$, or we get the zero vector $\\mathbf{0}_W \\in W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequences of the rank-nullity theorem:\n",
    "- If $\\dim(\\text{Im}(V)) < \\dim(V)$, then $\\ker(\\Phi)$ is non-trivial\n",
    "    - That is, the kernel contains more than the zero-vector and $\\dim(\\ker(\\Phi)) \\ge 1$\n",
    "- If $\\dim(\\ker(\\Phi)) \\ge 1$ then $\\mathbf{A}_\\Phi\\mathbf{x} = \\mathbf{0}$ has *infinitely many* solutions\n",
    "    - This is the same as the matrix being *under-determined*, i.e. $m < n$. Here the column space spans a smaller subspace than the original vecotr space. So the transformation $\\mathbf{A}_\\Phi \\mathbf{x} = \\mathbf{b}$ has no solutions and homogeneous system $\\mathbf{A}_\\Phi \\mathbf{x} = \\mathbf{0}$ has infinitely many solutions (the solution space is the entirety of the null space).\n",
    "    - This is equivalent to the condition that the determinant is equal to 0\n",
    "    - So, when the null space has a dimensionality greater than zero than the dimensionality of the image is less than the number of columns in the matrix. This means that some dimension(s) of the original space get squished down to zero as a result of the transformation. Because entire dimensions are being squished to zero, infinitely many vectors are squished to zero, hence infinitely many solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Affine Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine spaces are spaces that are offset from the origin - meaning that they are *no longer vector subspaces*. \n",
    "\n",
    "**Definition of Affine Subspace:**\n",
    "- Let $V$ be a vector space with $\\mathbf{x}_0 \\in V$ and $U \\subseteq V$. Then the subset $L$ is an *affine subspace* (or *linear manifold*) of $V$ with:\n",
    "$$L = \\mathbf{x}_0 + U \\coloneqq \\{\\mathbf{x}_0 + \\mathcal{u}:\\mathcal{u} \\in U \\} \\\\ \\ \\\\ = \\{\\mathcal{v}\\in V | \\exists \\mathcal{u} \\in U : \\mathcal{v} = \\mathbf{x}_0 + \\mathcal{u}\\} \\subseteq V$$\n",
    "$U$ is called the *direction* or *direction space* and $\\mathbf{x}_0$ is called the *support point*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "- An affine subspace excludes $\\mathbf{0}$ if $\\mathbf{x}_0 \\notin U$. Therefore, an affine subspace is not a vector subspace of $V$ for $\\mathbf{x}_0 \\notin U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine subspaces may be described by ***Parameters***. For an affine space $L = \\mathbf{x}_0 + U$ of $V$, every element $\\mathbf{x} \\in L$ may be uniquely described as:\n",
    "$$\\mathbf{x} = \\mathbf{x}_0 + \\lambda_1 \\mathbf{b}_1 + \\cdots + \\lambda_k\\mathbf{b}_k$$ \n",
    "Where the $\\lambda$ coefficients are the ***Parameters*** and the $\\mathbf{b}$ vectors are the ordered basis vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vector spaces $V,W$, linear mapping $\\Phi:V \\rightarrow W$, and $\\mathbf{a} \\in W$: $$\\phi: V \\rightarrow W \\\\ \\ \\\\ \\mathbf{x} \\rightarrow \\mathbf{a} + \\Phi(\\mathbf{x})$$\n",
    "The mapping $\\phi$ is an *affine mapping* from $V$ to $W$, and the vector $\\mathbf{a}$ is called the ***Translation Vector*** of $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7\n",
    "2.9\n",
    "2.10\n",
    "2.12\n",
    "2.14\n",
    "2.15\n",
    "2.17\n",
    "2.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 2.7\n",
    "- convert to augmented matrix and bring to reduced echelon form through elementary operations\n",
    "    - Solve REF system of linear equations subject to the constraint that $\\sum x_i = 1$\n",
    "    - Find that: $x_1 = x_2 = 3/8; \\ x_3 = 2/8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.375 0.375 0.25 ]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[6, 4, 3], [6, 0, 9], [0, 8, 0]])\n",
    "x = np.array([3/8, 3/8, 2/8])\n",
    "print((A @ x.T) / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 2.9\n",
    "Determine whether the sets are subspaces of $\\reals^3$\n",
    "- $A=\\{(\\lambda, \\lambda + \\mu^3, \\lambda - \\mu^3)|\\lambda,\\mu\\in\\reals \\}$\n",
    "    - We may substitut $v=\\mu^3|v\\in \\reals$\n",
    "    - Then we can represent the set as two vectors: $\\mathbf{\\lambda} = [1, 1, 1]^\\intercal$ and $\\mathbf{v} = [0, 1, -1]^\\intercal$\n",
    "        - These vectors include $\\mathbf{0}$ and exhibit closure in $A$ under $+, \\cdot$; so, they are a subspace of $\\reals^3$\n",
    "- $B = \\{(\\lambda^2, -\\lambda^2, 0) | \\lambda \\in \\reals\\}$\n",
    "    - For any $\\lambda$, the vector $\\mathbf{\\lambda} = [\\lambda^2, -\\lambda^2, 0]^\\intercal$ may be represented as $[1, -1, 0]^\\intercal$. Multiplying by the scalar $-1$ yields the vector $[-1, 1, 0]^\\intercal \\notin B$. So, $B$ is not a subspace since it does not satisfy closure under scalar multiplication\n",
    "        - Explicitly, for all $\\lambda\\in\\reals$, we cannot reach any scaled vector of $-[\\lambda^2, -\\lambda^2, 0]^\\intercal$ without *leaving* the subset of vectors defined by $B$ - so $B$ cannot be a vector subspace\n",
    "- $C = \\{(\\xi_1, \\xi_2, \\xi_3) \\in \\reals^3 \\ |  \\ \\xi_1 - 2\\xi_2 + 3\\xi_3 = \\gamma, \\ \\gamma \\in \\reals \\}$\n",
    "    - Let's explicate this: any three-dimensional vector of the set $C$ exists in $\\reals^3$ and is subject to the constraint that the combination of its elements equals $\\gamma \\in \\reals$ through $\\xi_1 - 2\\xi_2 + 3\\xi_3 = \\gamma$. We are not given the value of $\\gamma$, but in order for $C$ to be a vector space, it *must* contain the zero-vector $[0, 0, 0]^\\intercal$. At this vector, $\\gamma = 0 - 2(0) + 3(0) = 0$; therefore, $\\gamma = 0$. Using this constraing, we may determine a minimum spanning set of vectors for $C$, such as $\\{[3, 0, -1]^\\intercal, [0, 3, 2]^\\intercal \\}$. Any scaled linear combination of these vectors satisfies the constraint and is real. Therefore, the space spanned by these basis vectors is a non-empty subspace closed under vector addition and scalar multiplication. So, $C$ is a subspace of $\\reals^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 * x + l2 * y = [21 24  9]\n",
      "gamma = 21 - 2 * 24 + 3 * 9 = 0\n"
     ]
    }
   ],
   "source": [
    "# demo of C\n",
    "x = np.array([3, 0, -1])\n",
    "y = np.array([0, 3, 2])\n",
    "\n",
    "l1 = 7\n",
    "l2 = 8\n",
    "c = l1*x + l2*y  # linear combination\n",
    "gamma = c[0] - 2*c[1] + 3*c[2]  # constraint\n",
    "\n",
    "print(f'l1 * x + l2 * y = {c}')\n",
    "print(f'gamma = {c[0]} - 2 * {c[1]} + 3 * {c[2]} = {gamma}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $D = \\{(\\xi_1, \\xi_2, \\xi_3) \\in \\reals^3 \\ | \\ \\xi_2 \\in \\mathbb{Z}\\}$\n",
    "    - This one is straightforward. $\\xi_2$ is given to be an integer. For $D$ to be a vector space it must satisfy closure under vector addition and scalar multiplication. So, any scalar multiple of an element of $D$ must also be an element in $D$. We can easily see that this condition is not satisfied; e.g. for cases like $\\frac{1}{2}[0, 1, 0]^\\intercal$. So, $D$ is not a subspace of $\\reals^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10\n",
    "Are the sets of vectors linearly independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **A.** $$x_1 = [2, -1, 3]^\\intercal \\\\ x_2 = [1, 1, -2]^\\intercal \\\\ x_3 = [3, -3, 8]^\\intercal$$\n",
    "    - Let's combine these into a matrix of column vectors an bring to REF through elementary row operations. The matrix may be reduced to: \n",
    "    $$ \\begin{bmatrix} 2 \\ \\ \\ \\ \\ 1 \\ \\ \\ \\ \\ 3 \\\\ -1 \\ \\ \\   1 \\  -3 \\\\ 3  \\ -2 \\ \\ \\ \\ 8\\end{bmatrix} \\rightarrow \\begin{bmatrix} 1 \\ \\ \\ 2 \\ \\ \\ 0 \\\\ 0 \\ \\ \\ 0 \\ \\ \\ 0 \\\\ 0 \\ \\ \\ 0 \\ \\ \\ 0 \\end{bmatrix}$$\n",
    "    So, the set of vectors are not independent\n",
    "\n",
    "- **B:** $$x_1 = [1, 2, 1, 0, 0]^\\intercal \\\\ x_2 = [1, 1, 0, 1, 1]^\\intercal \\\\ x_3 = [1, 0, 0, 1, 1]^\\intercal$$\n",
    "    - Again, combining these into a matrix of column vectors and bringing to RREF yields:\n",
    "    $$\\begin{bmatrix} 1 \\ \\ 0 \\ \\ 0 \\\\ 0 \\ \\ 1 \\ \\ 0 \\\\ 0 \\ \\ 0 \\ \\ 1 \\\\ 0 \\ \\ 0 \\ \\ 0 \\\\ 0 \\ \\ 0 \\ \\ 0 \\end{bmatrix}$$\n",
    "    So, the set of vectors are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12\n",
    "We are given two subspaces $U_1, \\ U_2$ and their spans and are asked to determine a basis for their intersecion $U_1 \\bigcap U_2$. We haver:\n",
    "$$ U_1 = Sp\\{[1, 1, -3, 1]^\\intercal, [2, -1, 0, -1]^\\intercal, [-1, 1, -1, 1]^\\intercal\\} \\\\ U_2 = Sp\\{[-1, -2, 2, 1]^\\intercal, [2, -2, 2, 1]^\\intercal, [-3, 6, -2, -1]^\\intercal\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intersection of these subspaces is a subspace within which all vectors can be represented by a linear combination of the vectors in $Sp[U_1]$ ***and*** by a linear combination of the vectors in $Sp[U_2]$. So, to define this sapce we must find the minimum spanning set of vectors for all linear combinations of $Sp[U_1]$ that are *also* linear combinations of $Sp[U_2]$... This set can be represented by the simultaneous equations:\n",
    "$$\\alpha(1, 1, -3, 1) + \\beta(2, -1, 0, -1) + \\gamma(-1, 1, -1, 1) = \\delta(-1, -2, 2, 1) + \\theta(2, -2, 2, 1) + \\rho(-3, 6, -2, -1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
