{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "height",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fav_color_blue",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fav_color_green",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fav_color_red",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "gender_female",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e2152686-2277-442c-833c-9a04a75b8ab9",
       "rows": [
        [
         "0",
         "1.6",
         "88",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "1",
         "1.6",
         "76",
         "False",
         "True",
         "False",
         "True"
        ],
        [
         "2",
         "1.5",
         "56",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "3",
         "1.8",
         "73",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "4",
         "1.5",
         "77",
         "False",
         "True",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>fav_color_blue</th>\n",
       "      <th>fav_color_green</th>\n",
       "      <th>fav_color_red</th>\n",
       "      <th>gender_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6</td>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.6</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>56</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.8</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight  fav_color_blue  fav_color_green  fav_color_red  \\\n",
       "0     1.6      88            True            False          False   \n",
       "1     1.6      76           False             True          False   \n",
       "2     1.5      56            True            False          False   \n",
       "3     1.8      73           False            False           True   \n",
       "4     1.5      77           False             True          False   \n",
       "\n",
       "   gender_female  \n",
       "0          False  \n",
       "1           True  \n",
       "2           True  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy data\n",
    "df = pd.DataFrame({\n",
    "    'height': [1.6, 1.6, 1.5, 1.8, 1.5, 1.4],\n",
    "    'fav_color': ['blue', 'green', 'blue', 'red', 'green', 'blue'],\n",
    "    'gender': ['male', 'female', 'female', 'male', 'male', 'female'],\n",
    "    'weight': [88, 76, 56, 73, 77, 57]\n",
    "})\n",
    "\n",
    "# encode the categorical columns\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "df['fav_color'] = df['fav_color'].astype('category')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['fav_color', 'gender'])\n",
    "df.drop(columns=['gender_male'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction (average weight): 71.17\n",
      "MSE: 84.79\n",
      "Final MSE: 10.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "height",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fav_color_blue",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fav_color_green",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fav_color_red",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "gender_female",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "pred_weight",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "687e0ad7-e250-4730-bd62-16d10d0524de",
       "rows": [
        [
         "0",
         "1.6",
         "88",
         "True",
         "False",
         "False",
         "False",
         "83.24576946923652"
        ],
        [
         "1",
         "1.6",
         "76",
         "False",
         "True",
         "False",
         "True",
         "74.82145769180512"
        ],
        [
         "2",
         "1.5",
         "56",
         "True",
         "False",
         "False",
         "True",
         "60.642299868387994"
        ],
        [
         "3",
         "1.8",
         "73",
         "False",
         "False",
         "True",
         "False",
         "72.55539809778476"
        ],
        [
         "4",
         "1.5",
         "77",
         "False",
         "True",
         "False",
         "False",
         "75.09277500439762"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>fav_color_blue</th>\n",
       "      <th>fav_color_green</th>\n",
       "      <th>fav_color_red</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>pred_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6</td>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>83.245769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.6</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>74.821458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>56</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>60.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.8</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>72.555398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>75.092775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight  fav_color_blue  fav_color_green  fav_color_red  \\\n",
       "0     1.6      88            True            False          False   \n",
       "1     1.6      76           False             True          False   \n",
       "2     1.5      56            True            False          False   \n",
       "3     1.8      73           False            False           True   \n",
       "4     1.5      77           False             True          False   \n",
       "\n",
       "   gender_female  pred_weight  \n",
       "0          False    83.245769  \n",
       "1           True    74.821458  \n",
       "2           True    60.642300  \n",
       "3          False    72.555398  \n",
       "4          False    75.092775  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'weight'\n",
    "features = df.columns[df.columns != target]\n",
    "\n",
    "# 1. Take the average of the target variable (weight) as the baseline prediction \n",
    "avg_wt = df[target].mean()\n",
    "print(f\"Baseline prediction (average weight): {avg_wt:.2f}\")\n",
    "\n",
    "# 2. Fit a regression tree on the ERRORS of the baseline prediction - these errors are called Pseudo-Residuals\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "pseudo_residuals = df[target] - avg_wt\n",
    "tree = DecisionTreeRegressor(max_leaf_nodes=4, random_state=42)\n",
    "tree.fit(df[features], pseudo_residuals)\n",
    "p_residuals = tree.predict(df[features])\n",
    "\n",
    "# 3. Add the baseline prediction to the Pseudo-Residuals weighted by a learning rate to update the weight predictions\n",
    "learning_rate = 0.1\n",
    "df['pred_weight'] = avg_wt + p_residuals * learning_rate\n",
    "\n",
    "# 4. Compute new pseudo-residuals using the updated weight predictions\n",
    "pseudo_residuals = df[target] - df['pred_weight']\n",
    "\n",
    "# 5. Fit a new regression tree on the new pseudo-residuals\n",
    "tree = DecisionTreeRegressor(max_leaf_nodes=4, random_state=42)\n",
    "tree.fit(df[features], pseudo_residuals)\n",
    "p_residuals = tree.predict(df[features])\n",
    "\n",
    "# 6. Add the new pseudo-residuals to the previous predictions to update the weight predictions again\n",
    "df['pred_weight'] += p_residuals * learning_rate\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(df[target], df['pred_weight'])\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "\n",
    "# Repeat steps 4-6 until convergence or a set number of iterations\n",
    "\n",
    "i = 0\n",
    "while (i < 10) and (mse > 10):\n",
    "    # Compute new pseudo-residuals using the updated weight predictions\n",
    "    pseudo_residuals = df[target] - df['pred_weight']\n",
    "\n",
    "    # Fit a new regression tree on the new pseudo-residuals\n",
    "    tree = DecisionTreeRegressor(max_leaf_nodes=4, random_state=42)\n",
    "    tree.fit(df[features], pseudo_residuals)\n",
    "    p_residuals = tree.predict(df[features])\n",
    "\n",
    "    # Add the new pseudo-residuals to the previous predictions to update the weight predictions again\n",
    "    df['pred_weight'] += p_residuals * learning_rate\n",
    "\n",
    "    mse = mean_squared_error(df[target], df['pred_weight'])\n",
    "    # print(f\"Iteration {i+1}, MSE: {mse:.2f}\")\n",
    "    i += 1\n",
    "\n",
    "print(f\"Final MSE: {mse:.2f}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Regression Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Data $\\{x_i, y_i\\}^n_{i=1}$ and a differentiable loss function $L(y_i, F(x))$\n",
    "\n",
    "In the toy data example above, we didn't use a loss function explicitly, we simply computed the pseudo-residuals directly and then fit to them. A commonly used loss function for regression GBM is: $$\\frac{1}{2} (y_i - F(x))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize the model with a *constant value*\n",
    "\n",
    "The constant value used for initialization is denoted $F_0(x)$ and is chosen to minimize the sum of the loss function for all observations:\n",
    "$$F_0(x) = \\argmin_\\gamma \\sum_{i = 1}^n L(y_i, \\gamma)$$\n",
    "\n",
    "For the loss function proposed above, this initial may be found conveniently by taking the sum of the first derivatives of the function at each observation:\n",
    "$$\\frac{d}{dF_0(x)} \\bigg[ \\frac{1}{2} (y_i - F_0(x))^2 \\bigg] = -(y_i - F_0(x))$$\n",
    "Setting the sum of these derivatives equal to zero and solving yields the optimal initialization:\n",
    "$$-\\sum_{i=1}^n y_i - nF_0(x) = 0 \\ \\implies \\ F_0(x) = \\frac{1}{n}\\sum_{i=1}^n y_i$$\n",
    "This is simply the average of the target value. However, for other loss functions the optimal initial predicted value may be different than the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **A**: Compute the gradient of the loss function w.r.t. the predicted target values \n",
    "$$r_{im} = -\\bigg[ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\bigg]_{F(x) = F_{m-1}(x)}, \\ i=1,...,n$$\n",
    "\n",
    "When the squared error loss is used, then the gradient is simply the residuals (aka. the pseudo-residuals) computed in the toy data example. So, in that example we were indirectly boosting using the squared error loss. However, it is not always that case that the gradient of the loss function will be the residuals. Using the gradient explicitly instead of the residual improves the generalizability of gradient boosting machines. Additionally, using the gradient loss function instead of the residuals *does not change* the error-minimizing properties of boosting machines since fitting to gradients still enables boosting machines to reduce errors w.r.t. the chosen loss-function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **B**: Fit a regression tree to the $r_{im}$ values and create terminal regions $R_{jm}, j=1, ..., J_m$\n",
    "Basically, just fit a regression tree to the gradient (psuedo-residuals) from the previous iteration of the loop. The \"terminal regions\" are simply the leaves of this tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **C**: Compute the output values (predictions) for each terminal region\n",
    "The predictions from the tree are not simply the average values of the target variable at each leaf. Rather, they are the value at each leaf that minimizes the sum of the loss functions for each obeservation within the leaf:\n",
    "$$\\gamma_{jm} = \\argmin_\\gamma \\sum_{x_i\\in R_{ij}} L(y_i, F_{m-1}(x) + \\gamma), \\ j=1,...,J_m$$\n",
    "Like in Step 1, these values may often be found by simply taking the first derivatives of the summations. For more complex loss functions, algorithms like gradient descent may be used instead. It happens that the optimal prediction for the squared error loss is the average predicted target value in each terminal leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **D**: Update\n",
    "Update the predicted target values using the predicted pseudo-residuals:\n",
    "$$F_m(x) = F_{m-1}(x) + \\nu \\sum_{j=1}^{J_m} \\gamma_{jm}I(x\\in R_{jm})$$\n",
    "Where $\\nu$ is the learning rate and $I(\\cdot)$ is an indicator function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Output $F_M(x)$\n",
    "Simple as that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Data $\\{x_i, y_i\\}^n_{i=1}$ and a differentiable loss function $L(y_i, F(x))$\n",
    "This is the same criteria as the regression context.\\\n",
    "A common loss function is cross-entropy aka. negative log-likelihood loss:\n",
    "$$-y_i \\ln(\\frac{p}{1-p}) - \\ln(1 - p)$$\n",
    "Note that this is binary cross-entropy, so not a loss-function that is suitable for multi-class predictions.\n",
    "This loss function may easily be expressed in terms of the log-odds rather than in terms of probability:\n",
    "$$-y_i \\ln(\\text{odds}) + \\ln(1 + \\exp\\ln(\\text{odds}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1:** Initialize the model with a constant value\n",
    "As with the regression context, the intial value is chosen to minimize the initial sum of loss functions:\n",
    "$$F_0(x) = \\argmin_\\gamma \\sum_{i=1}^n L(y_i, \\gamma)$$\n",
    "For the log-loss this may be solved analytically and is simply the unconditional log-odds of the target variable, i.e.:\n",
    "$$F_0(x) = \\ln\\big(\\frac{p}{1-p}\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2**: Loop for $m=1$ to $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **A**: Compute the gradient of the loss-function (pseudo-residuals)\n",
    "$$r_{im} = -\\bigg[ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\bigg]_{F(x) = F_{m-1}(x)}, \\ i=1,...,n$$\n",
    "For the log-loss, the gradient is:\n",
    "$$r_{i} = y_i - \\frac{e^{\\ln(\\frac{p}{1-p})}}{1 + e^{\\ln(\\frac{p}{1-p})}} = y_i - p$$\n",
    "To be more precise, $p$ is now a conditional probability for observation $i$, so: $$y_i - P(y_i|x_i)$$\n",
    "At $m=1$, the conditional probability is equal to the unconditional probability because the initial prediction is simply the unconditional probability given by the unconditional log-odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **B**: Fit a *regression* tree to the gradient (pseudo-residuals)\n",
    "Fit a regression tree to the $r_{im}$ values and create terminal regions (leaves) $R_{jm}, j=1,...,J_m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **C**: Compute output values for each terminal region\n",
    "The output-values for each region are again found by minimizing the loss function within the region:\n",
    "$$\\gamma_{jm} = \\argmin_\\gamma \\sum_{x_i \\in R_{ij}} L(y_i, F_{m-1}(x_i) + \\gamma), j=1,...,J_m$$\n",
    "Sometimes these are analytically solvable, other times they are algorithmically approximated.\\\n",
    "For the log-loss, the output values are given by: $$y_{j} = \\frac{\\sum r_{ij}}{\\sum p_{ij}}$$\n",
    "Where $r_{ij}$ is the $i^\\text{th}$ pseudo-residual for leaf $j$ and $p_{ij}$ is the $i^\\text{th}$ predicted-probability for leaf $j$.\\\n",
    "At $m=1$, $p_{ij} = \\frac{e^{F_0(x)}}{1 + e^{F_0(x)}} = p, \\ \\forall i, j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **D**: Update predictions\n",
    "Update the predicted probabilities:\n",
    "$$F_m(x) = F_{m-1}(x) + \\nu \\sum_{j=1}^{J_m} \\gamma_{jm}I(x\\in R_{jm})$$\n",
    "Where $\\nu$ is the learning rate and $I(\\cdot)$ is the indicator function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3**: Output predictions $F_M(x)$\n",
    "Simple as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
